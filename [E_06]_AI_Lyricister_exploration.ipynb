{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9a70865",
   "metadata": {},
   "source": [
    "# 평가 조건\n",
    "1. 데이터의 전처리 및 구성과정이 체계적으로 진행되었는가?\n",
    " - 특수문자 제거, 토크나이저 생성, 패딩 처리의 작업들이 빠짐없이 진행되었는가?\n",
    "2. 가사 텍스트 생성 모델이 정상적으로 동작하는가?\n",
    " - 텍스트 제너레이션 결과로 생성된 문장이 해석 가능한 문장인가?\n",
    "3. 텍스트 생성모델이 안정적으로 학습되었는가?\n",
    " - 텍스트 생성모델의 validation loss가 2.2 이하로 낮아졌는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94311302",
   "metadata": {},
   "source": [
    "# 1. 모듈 임포트 및 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e37195a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      "Examples:\n",
      " ['', '', '[Spoken Intro:]']\n"
     ]
    }
   ],
   "source": [
    "import os, re\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import OrderedDict\n",
    "\n",
    "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*' #os.getenv(x)함수는 환경 변수x의 값을 포함하는 문자열 변수를 반환합니다. txt_file_path 에 \"/root/aiffel/lyricist/data/lyrics/*\" 저장\n",
    "#*는 해당 파일 안에 있는 모든 것을 불러오겠다는 의미\n",
    "\n",
    "txt_list = glob.glob(txt_file_path) #txt_file_path 경로에 있는 모든 파일명을 리스트 형식으로 txt_list 에 할당\n",
    "\n",
    "raw_corpus = [] \n",
    "\n",
    "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담습니다.\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines() #read() : 파일 전체의 내용을 하나의 문자열로 읽어온다. , splitlines()  : 여러라인으로 구분되어 있는 문자열을 한라인씩 분리하여 리스트로 반환\n",
    "        raw_corpus.extend(raw) # extend() : 리스트함수로 추가적인 내용을 연장 한다.\n",
    "\n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "843301a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(txt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62ac73db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/aiffel/aiffel/lyricist/data/lyrics/michael-jackson.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/blink-182.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_list[:2]"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVAAAADNCAYAAADuZyjwAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAACHiSURBVHhe7d0PcBVX3TfwX+gznai1UoUx0GoTSlUiVKJ1JJmnOk3gGQlSbSjMkEicNpQZm5R2CDJ9G9pHIemD0PBqG6pToY+GIR1bE/88Jmgh6at9DI60pE4rqIQk0pbQggWtGmwr+57fuXtuzt2c3bu7uTfZm/v9zCx39+w5Z8/u3vvLObt7LzmWQAAAENg0+xUAAAJCAAUACAkBFAAgJARQAICQEEABAEJKaQB988036cKFC/bS+FRXV1NOTg5dfvnlNDAwYKea9fX10Tve8Q6Z/6677rJTiX7zm9/IND/T9OnTad++fXZJsy984Qsy7+zZs+nw4cMy7a233qI1a9aMqc9tuuqqq2Q5NydOnKAFCxbIvB/60Ifs1Jj3ve99Y+pzm+677z66ePGiXXKsBx54IJ63q6vLTgWAIFIaQDlg7d271/ODCwAwVaTsOVDuiW3dulX24rhHyD3H8eAeKAfjd7/73fT888/TnDlz7DVj8fZKSkpk73f9+vX0zW9+U6YfP36cNm3aJOeTeec730nr1q2jz3zmM3bKWNwD/fGPf0yzZs2Sr5/85Cfp7bffppaWFvrFL35h5/LGvcjdu3fbS2NxD5S38+KLL9K1115Lf/zjH+01JHu6f/vb3+wlbytXrqTVq1fLHqYJ90AbGhrkfGdnJ5WXl8t5AAiAA2gqvP7665YYcnIwtr7xjW/YqeGJYCHrEgHUEkHFTjU7cuSIlZubK/OLAGqnpt7nP/95uQ0RQC3R27ZTU6u/v9+aP3++3I4IoHZq6jU1Nclt8CQCqJ0KAEGkbAg/MjJC586dk/M7duyg8+fPy3kAgKkqZQH0ve99L4kempx/5ZVX6IknnpDzAGn36yZ5qaLp1/ayL6epbRXfRGuiQ3bKxDpETXwTb2vyrZ9+fIVo5wpqe9lOSDn7WKxqE3MQRMoCqBhC07Jly+Q1Pvb9738/3iMFAEi98zS4v5mafhgi7J8fpK4dTdQxzj9K4w6gfFPj73//u5z/1Kc+Rdddd52c/93vfke/+tWv5DxAWi1q4Gv51LDIXp5i8la3i/1rp0rvJ+Cyz8tdtLF8Ix0J8eTk6f0badmmIzTehy7HHUB//vOf00MPPSTn+e4090KnTZtGr732mlz3j3/8Q64DAJhqxhVA33jjDRkkm5ub4w+786MzV1xxhewR/OQnP6FXX31VpgO4Utcw//c8Hdqxlkqu5WuTs6jwpo3UNSTWvy2GW1urqHAWp8+hktt2UZ/+NJfxGuh5OvbDJlpbPEeuy5lVSMvu2EU9htHeyOkear6thOaofJva6JjzHuj5Y9SxdS2Vqfq4faVrxfDxmKEXI/bj4TpatmBWLO+1JbR2Rw+dftteHZDxGmiQ9rx9mnqc7dnaMXYfE4hjvr5E5C+R50U5/XQzrS0tpFlym+JcrNpIbS+Orej8ix3UpI6pPJd1tOvpxIMf368hPr+J591UZwI+5x+oog4x21HJ+8XH5wL1bOJ50eZn9aOg0pfRnn6iQ1tzaFalLElVHxDbXNUWyxbCuALoyy+/LAPon//8Z/kMKONv6fDzlOzkyZP05JNPynmAZDq/Uk5Vhwuo7qFu6myroYLDzbRsdR1tvK2Mml8qoca2bmrfXkSn/7uOyjd1iTDl5oL4kJRTYUULDS6op/YeUd/OKso9UEdlReJDl3Ddq4WqitZSb0EdtYh87Rvm0bEdIlhX7hEhxHahj5qWFtKK1nNUtO5B6ub62jZSCXXS5opS2rhfb8kgtVXPo5L17XSheLPcdvv6QhrcWUZFt7WN1jkeQdtzWxGVre+i3FXN1Kna88gKKlzaRH3GMex56rm3ipY9TNT4TBc1/Pv0WOr/1FFR6YM0vLCedol6ursaqfTCPqpaUE7Nz8ss0uCTa+njC1ZQy1Ah1Xdwvmaqyu2iutIiUWefI8APUsvqEqp7QZ33Opp3TORfUON902xuBXU/0UClYrb0vnZxDDZT6YxcKr2/gxoWHqLNdzbH9+30kzVUtYOosq2FauYSzVspjsF9siQ1PCHat4nn/eA/8Btp1/PaHsiHmULatm1b/FnCzZs326mWJYbv1owZM2T61VdfbZ0/f95e4x+eA82i50APNcbasnKfNWAnsYFHS2V60X291oidxnrv43Y3WL32sirfeMhe7nvQKhLL5Y/qtQmD+6yKucVW5WNHxcKwtW8l15Nn1T+l1y7eT9uLRHqFte+l2PLIUw1W8dwi68G+2HLcmXarhtu9Jd4S61xHjWxLRWvitkdEG4u5TY+p9F6r0VHWzXBbxTjbM3YfR54RdcwvtRpkun0sxPEfts5ZvVuKRZlicTz1MsNW+xqR5+bEc2S90WnV5s2zSh85Else6bYa8mJ1OY6AOG98XMut3cdjKbH9Gnt+1fmraBu2E1y8JM6nIZ861sU7RZvEOa8U7clb0y72YJTzmCZ3zur+P3xcxL7llVot9rH/N5EQCt88evTRR+X8zJkz6Y477pDzjJcrKyvltdE//elP8htFdXV19tqJc/r0aXr88cftJW+XXnoplZaW0rx58+wUf/hrq9wL//3vf2+neLvsssvo9ttvt5eCeeSRR+if//ynveSNb+gVFxeLYYv5m0hRVLG8mArseVawgHsGPVT+H8WUG0uS8q4VHxs6RoOih1JsuLHS9/Q+6qNaalyp1ybkV1L78Up7QQ0na2jFEr12oqJi/lZWk6yfRP25Sxqp97gId04zZiW0l+vs+eEe8VpPtY5t5y6qobqVm6nq8R4avFX0ru30MPy35zz1HhDtWfggVTn2MfffRR0v2Atx56hH9Nyr7r9ADc/0UsMivcx0mn5VHtF/tVDzfxdQ/Upxri4TyZeVU8vw6LfYLogea5M4tPW3VzjakkvF1bVUKobqbU8Pip7g6Frn+aV80YMXL+1Dw+Jfsc2AchfVU/OWTirZUEtl/zMo3kH11P1IRYiaFO6Rl1PZf6lHzvLoilinXITTkL797W9b4sMpI/Ldd99tp4765S9/aYlAKtdfd9111rlz5+w1/qSiB3r48GGZ7md6//vfb7W1tdklzUw90DfffNO69dZbjXWapjlz5shybrx6oLxdU52m6atf/ar1r3/9yy45VhR7oGN6HM6epW1M78GRr3cL71fjaA/VSPVADflctmuNnLOGj/Va3T3t1u7t9VbNjfMs8aHUenxHrEbufS1psMTQXeRLnFpu5+2pnrOjB2pvM2Gy17n2lpK2R+9ZelHHYnQqfuBIYq+QDXZa9TfmxfPkzS+3arfvs7qPj362vXt2ifuseqBjjrPz2Lhx6YFKI6KOhdzOeVZDz5g9MbfzDVFmkdj3Ozu13rPW8+Qpr9LaN2ivEkJdA+Xe586dO+WNIn6A/otf/KK9ZhT35G644QbZA+Je6P79++01ABnm7UHq2FBGs95xBc2aV0JlpRtpz4HzNP3mctlTGnUh1rE90EQrSstEvsSp7jucJ9ZzHhff7Qkor5QaDw2TGMLToXtrqTnhRoyQX04P9gzScF877b6vlkouO0a7NlVR2bXzqGyH89qm2Yj9mna/76VOeV32GO15ssfjerlygbruLaHNvyY69PAyqlrfRYNvO3qeeZW079A+qsyPLbJQQ/if/vSn8gYSKysro4KCsQMSfqD+s5/9rBze/vWvf5U/mcY/WPGe97zHzpF+/NNx/KMZfvAQfuHChfaSf5dccon84Q7+CTo/eAgf1ubNmwMN4TNp+J5KuZcViX+H6Rx/atRQSxqkPf9RRnsW7aaeLYV2WnJ9D1fRiv8r+o5dA7TxxgKaHh9vHqKm9c3yTnBMAc1bI17+to8GOiqDDdPls6yxH3dJxn97cmn6DPEiguKYwfCFHtpYUEeDD7RT+61XxNJuqKGaRXmUN7+ZGjpEMLmzmcqfbqCihPF1LuUtrKAanraIxbN9tOuOj1Pdpn3Ue2cRlczgvW6mI8cuUOVVCQWJ+o/Kb32V5oUfTPvTR81f3kiHFjVS+7qjVHtbDW1eeoxalie8GRxyqXyDCI5PVlGb+CPIQbRsfwEN9tu3/QzBU4p1RP37y1/+Yq1evVoO3y+//HJr9+7d1sWLF+21iV555ZX4D4yIYCaH1H7hJlL23URK1RA+fhPCeSPnmQaZXtPBQ06/Q3iVT7tpZTvXE6uPvtwpBnoxA4+Vi7zOGzCCPTwsWL7b4ltY4W8iBWtP7CZSkdXwTGJ7Blq5TnUjauxQf+Spenk5QN6IkY5YLcuLrQIxvE2sacTq/orWnqQ3kYqtlhdiKeMewg+3W5UiX+J5HrGOPGDfBDvMLeWbX3ly6N2uDdeHn6gUecQx1Ybjkn3TidsVnxzDdl3gIfzRo0ept7dXDt+vvPJK2cvkng7/lBzfsPnud78bn5566im6+uqrZTnusXLPFSDtFtbSLjEM7agWw9t1u6jj6R7qeHgtLVvZRMM3tlDtzV49Eac8Kl4au6lUf1szte3voZ79bdR8xzL6eOkeGubO1Nnz8eFrwa0ttG/NIG0uLqQVW9uoS2y76/FmWntThRgeFlPNvVUU7DalU7D2TL+5QbRnmJpuUO3poratK6isuoMK7mwUPUk7o0Puks2058t5dGiDGMrLobDoXd4o+vAP19CydfZ2n+6gPRtWyEeEineuoGJZsJRqHqqhAtGTKyldS7t+GGtf06pCKtk6TKUPNFPNfM4YkP2sb8JvB+TNIh5HdDzeJs/xsbOiY/3rZqq99xAVP7CL6q/nHnAeVWxppkpqE+mjj5HlfUCWpH17O8R+HIslsny7p6k6yW49TyUWR/3hmxJbt26N3zy699577TWW1dramhi1DVN+fr7swfqBHih6oKF7oNI562hHo1WzqECuo7nFVs2WTmvgLXt1vCfn5ybSOevIY7VW+Xz7Boqoq+Iru63eYdGr2sK9mwarW++WvTVsdT9Ua1WobfNjPrc2Wu0v6DdSw/ZAWbj2qPzy5s9jR+K91PixcN5sekn08Lg3tuhB0f9kI7Fjqm5WUZ4178Yaq7HjqKNXKlr4QrvVeKvosap8y2utlp7E8xuoB2qfE+fxGvhJvVU+l7dBVv2P/5/s5dOiRuuIo0GxHneeVdmmeqsDVudXyu321dtpmsF2q3ZJrWvPUwkUQN944w3rwx/+sGwsD98HB2O1j4yMWAsWLIjtYJLJ72+FIoDi90AhZmwAhagINITnbxXxr7wzvvOuhueiZ0riAyl/pd008S+w87Oh7Otf/zqJXqicBwDIZL4DKF/j3LJli3xwXPQK6e67747f5X3Xu95Fy5cvp5tuusk4rVq1Sv7ICOfnHxnB1zsBfDh7LHadcW+HGH1+nArwa0yR4zuA/uhHP6KhIf5lB5JBkW8g+cWP7ixdulT+z5fcW+W6Xn/9dXstAJicP9RMVaUraPPxcmpsq43dpIFI8RVA+VeX1H/5y89xfu5zn5P/jbBf3PP89Kc/TR/5yEfk8nPPPScnAHA3ffluGub7FMc7qeHGIE8OwETxFUD5/0Dn/xmTFRYWyv8BUw3f/crLy5P/2yTj76j/7Gc/k/+PPABApkoaQPmbLwcOHKBTp07JH0pesmQJffCDH7TXBrNmzRr51U/W0dGB3woNiI/fzTff7Gtqa2uTz+oG9Z3vfIcqKiqMdZomgKwWuxnv7qWXXrI++tGPysdd+NGlP/zhD/aacPhn77gunrZv326njoXHmMY+xiT++Mh0PxMf5zA/JlJXVxd/ztfPBJDNkvZAe3p64o8u8Xe+xYdazod111130YwZM+QlAP65O/X/KQEAZJocjqL2PAAABOD7MSYAAEiEAAoAEBICKABASAigAAAhIYACAISEAAoAEBICKABASAigAAAhIYACAISUMzw8jG8iAQCEkPBVTv6ZuSuusP+PaAAA8IQhPABASAigAAAhIYACAISEAAoAEBICKABASAigAAAhIYACAISEAAoAEFJKH6Q/c2AL1e/tt5c011RT838upjPfq6ZtdA+1fmkmHfxaPfWWNNP9S2bamaLFdV+ExZtaqXq+vRB3Rtsnitj+xdomWi3PQ0KLzh6kLRtaKX9TM81uj/Y58UXuTy+V7LyfFs+w0wDSJPU9UA6Wra3Uqk/OD22mMO2LmMYGT29HxR+O6u8dtZcmw0z6WMlcohOnRChNdKavl/ppMV0fcJ8AYIKH8IVfEgHoS4X20lQ2kxb/Z2ukenIzi0poLh2kZ1+0E6Qz9Nvefpq7ZikVRrDNAFE3oQHUqycm11Xb06T21gLg4aJq89f20yk7OTZkrqYtB87ISwHbukVS97bJ3a8ZH6OSa4gOPqe14exvqffEXCop4qA52mbFeE5eFD3wrx2M92R5/8YsR/n86edM3y+1/99r1da3kr4n+vFoFfni6/mY6HnlNrbQwbP68mjZxOMT225s3RZRr+F4qnJaOkRD6gPoiVaqVydcTolvQhMZZIbUcLmZqoe2JXyQJ82YfRFT/E0s3vi7WonWNMeG9itEcDohVySYueR+uqdMzJTxtd/J7H3bw/juZ+PnQw7frymhjxmuFbqek/nX0+ITvfRbGRy4B0uiZ6sv99PiT0R1lBE7Z/mbYpdiWndW09zuH4wGOqFf/LG7Re3zNQdpm/aHY1v3YrrHXjd76GAsPSnvbZ458K3YtWlZ7y3i/GjX3cU26/fm29tspXvyxXKU/zhloQm4Blothode7A/dCnWdVAwlxXx/72/FmknmdT03ofcmzF8qPnCx2aiKDeOH6JQW7OaWfMw+7jqvczKTZl/TT6dOx/KdohK6pYRiy/KYRPl6auwyRfwa9ulT5LxNGLucwcR+5ssZ6ehzImCWXR9fx8fDH69tOs9BIS1dI/7I2Xibo+0Ra5dx8B39AwiTb0KH8GbiQyh6bge3a7287eLNarjhESnyg5BPs+O9t8QPXCTJYXw/9faJI+v8A5DA65zEerLyUsCLz9LB/NlUOCs/tszHJB5koinhskT7kPiD4oc4HkMiuM42Havk3LcZO875s1zOgdhm/9760bIbWsV7Tv0BhCiIQADlHk3s0aCEnl7Snusky5ut9eZY7A0fbbHgxz3Jox7D92TnRPZkh07R0eGh2HCdh/Vi+aDoMUV3+C6cPUg/6J5L1Tvt/akVXWdfYn8c+0+F+JPuuc3YcR4aNtUb2+ZcdYkoPuHxrCiJRACVPZr20Qvk8i921C+Y27251k57QCV7dLHZKJPB70QrbdvrNnxnSc7JjNmUf6KXftBLNDuPE8SHnXqpdygTHodSlx/EPnVyj86fwk+IIXt8+HxGHps4+cd09AmH2KNhOrdtjv5Bix3no7Rfe/aYt9m/d//oNWt5Qyn5PQWYOBEIoOJtxDda+AK5PVSRF+uj8Oyo6SaSmGI3uPja1j20mO+uc/qGU5TPN4sMYh8+kS8KfxTsu/F868c8fI/xPieFdH1ZP/WfUJcwuLcklvOjMnwXf9g2JJ4zeed7xmK6RZwjdWni2U+I86cFN0/zq+mesoO0Tdb3LaIS7Rqoo95vUYmo15ZkmzOXfJmqSR3nZ2m2dg2Ut9m8ZsjeZjXV7yXRk434yCzL4L/0AAiDH11qnz32m13jxL3M+lO3ZMnz0pkvEj1QgKiTw2f9mVEewufPHnfw5Esjo4/sxYbwYW9WwcRDDxTAl6PUWr2N4lc+7d93GHeo44fs5d1126Q/LwxBIIACAISEITwAQEgIoAAAISGAAgCEhAAKABASAigAQEgIoAAAISGAAgCElBBAp02bRm+99Za9BAAAXnIGBgbiD9JfeumldMkll9hLAADgJWdoaCgeQAEAwL+ckydPIoACAISQ8/LLLyOAAgCEkHPq1CkEUACAEKbl5OSQ3wkAAEblvPrqq/EeqPbLdgAAkMQ0DppqAgAA/3Jee+01Y+RUARVDdwAAM9cAqkPvFABgLPlVzmQ3itALBQAYK+fs2bOye6n3Mp3zCKAAAGPlnDlzZkwAVdyCKgAAaHfhFZ6/ePGinPR09EIBABLFbyKpQKoCpQqeehB14ycPAMBUI28iqQDIvwfKnMGTX70mAIBsJL+JxL1OPRg6552vGM4DANhDeL7eyTg46vOmVwAAiMk5ffq0jIwqcOoBVA+eat7Z+0RgBYBsJQOouuNumpzDe8W5DACQbXKGh4dFLIwN3a+88ko7OTMNDAzQnDlz7CUAgPSaxoFT9UABAMC/+H9rjAAKABAMfg8UACCk+IP0CKAAAMHIHijDw/EAAMGgBwoAEFKkr4E++uij9hwAQPTE78JHDYInAESdDKBRvP65bt06ew4AIJoi2wMFAIi6eADFTSQAgGDQAwUACEkGUPQ+AQCCQw8UACAkBFAAgJAQQAEAQkIABQAIKdIBFA/TA0CUoQcKABASAigAQEgIoAAAISGAAgCEhAAKABBSzsmTJy31XxsXFBTYyZPP+Xugfu7I4/+FB4CJFMkAysHTGTBNaU4IoAAwkTCEBwAIKZIBFA/QA0AmyIgeqJ/hOwDARIt8AEXwBICoinQARfAEgCiLbABF8ASAqItkAEXwBIBMkBE3kQAAoiiyD9KbJOuV4kF6AJhIkf0qZxgIoAAwkTCEBwAICQEUACAkBFAAgJAQQAEAQsqqAJqTkxOfYOLh+MNUk1U/qMwfXMuy7KVRzg+0KU8QbttJt8nablCZ0k6AZLLqB5VNH1y/aUFMVoAIs93JaOtkHR+AVMM1UEgLDpIAU10kA+hkfw9e9Y5UEOBXt4DgtU6n51FlnGXd0sfDq061bFrH/Kw3pQNki0h/E0m/Dprua6Bu6UwPqHo+fdltnnmtYyrNq5wfXnUrQbbB65hpvV7Oqw6ToPkBoipjvsqZrmugiilYmPKrNL/rnPn8lmOmvF686laCbMNtnZ/teAmSFyDKcA3Uxh9onvjDnSpeAUifACAzIYA6pCqIetWhgrU+TTX4wwDZIJIB1PkMaDql64OuAiMCCcDUhR5oEnoA5HnVW3QGR32dzk8QTbY+avzsu+lYAEw1+CaS4AxgKo/Kr9Z7ldXXmbajp6kyip6erB4vybbL3PKwZGWd3Molk6xegEyRMXfh/fATQBU/H2B80FMr6PEHiLqsGsLzh1ZNfuBDnlpBjz9A1OEaKABASAigAAAhIYACAISEAAoAEFJGBNDxPliv3/1lzmXIPn7eA3ifQDKRD6AT+a0k8C9TgguCIKQThvAALvC4FSQT6QDq5yfsUoV7Ks7eiqn34rdHo+pTk+Isb1rWJ51aNq1zo5fRXxVVl1e6aZ16da5LRpVxK2tK19O8yuj5mJp3pisq3Wu9U7IyTF/nlgemhqzogXJPQn9DO3sWKk3PNx56fUHq9VNOzzNezu05t+W2jpfVq5r3w7k9nvR69fWmtqj1bmXUpNbzvHpV8zqVribnNt14ldHb47c+yFyRDaAT1ftUb3gl6m98va3jlcq6wlJtyLTzYGLaB5jasuYaqPpATtSbmrelT36FLRfWRG5LnYNUb0vfh1TXDeAlkgF0Iq99pgsHC+ek0tWHnF9VuqLnV1O6qO2nezs6ta1UBjt9H9QEMBEi+//Cm6Tj/0TySvOb3ylZHrf6/ZYLyu/29OUgecdD1WOqz7nOlNdUTue23pTuTAuTR1/meeasA6aOjPg5O7890lT8r5xu88zvB8K0HVNdyfIwPc203g9VzlneWTdz21ayZT9MZfS0ZPPOV32dLtl6lqwcG08exumm9TB1ZM01UC/qje58s+vpQT4IznJ+y4YtF5a+PbUdnvdDL+tXsv0ztSeZIHWmm9oGb9Nv+yGzZdUPKgOkmzNQI5BObeiBAqSQ6n2iF5odEEABAEJCAAUACAkBFAAgJARQAICQsupBehPnYy9TzVTfv7DSeVz81h2kDalsL94TqRPZABrmq5xeAdTtTTOeN1MmvBHxYTFL53HxW3eQNrjlDbMf6dz3bIMhPABASFkRQPkvrnpV8zqVblrvla5eneu8mPKa6jalOZnS/FDl1HbUZGJap5adr8mY8pnqNqU5mdJMVH1q0nmtY6Z0t3x+udWpTyZuvU/16lbOjSpjKuuVrvMq51w3VWXMNdDxfheeT6jfIZBKc65LtuyH1/b8ziumNCdnHq86/eZV887XZEz5TPV6zSumNCevcsnq9DOvONNMeZizHsbLfsubBMmrmMqoNK+2BFnHTGlTTWR7oBww9cntxlI6pePkc538xlK83oTOvOMV5A2djrY469C3kY7tmejbcJOOtpjqjKKotiuqIhlA/fQ2Jwq/8dWUyZwf4GygAl+mn7uJpo5Z0OOmlwtaNlPhJpIHfhPwh1BNqabqT7covpknat/VuePtRfE4RI06L2rSqePITOdPL6emqS6SAXQyhusTid9YE/lhVm/mVG1T1aW/+pXKdgTB252sbcPUhR6oT+n44DkDj/MD7hWcwrQnSAAJ0pYwnHUF2Z7fffCbzykdbTHVGXWmNqr9cDseukzYx/GK7O+BOnuhfq6L+vlFeqaffNObQU/Ty7iVZ846kjFtV3GrU6Uz1Z5k2zXlUWnOdW55md86/PAq47U9Jch29XJMlTGVd6apsqZ8Cq8zlXOWUfQ6Vb4g5U30Ov0w1a+n6fWZ6jaVZyqvYsoz1eAHlSeY6Q2ZLbJ532FqwhB+gnHwyNYAks37DlMTAigAQEgIoAAAISGAAgCEhAAKABBSVjzG5Hy8gqmbGW6PZEA4OJ5m6TwufusO0oZUtjeK74lUtSljflDZlObk5zlQ50GL4snNZDieZuk8Ln7rDtIGt7xh9iOd+x5WqvYvY4bwUfqBEQDIbKkK6LgGKvBfHX3Sea1zo+d1K+NWn17OuV6lmda5MeVzppnq81POL1VObUdNJqZ1atn5mowpn6luU5qTKc1E1acmndc6Zkp3y+eXW536ZOLWO1OvbuXcqDKmsl7pOq9yznXJmPKrtCD1Zc0PKjM+KM43hlea3/xOzvLOMvqyaR3T05gzHzOlOSUr52deMaU5OfN41ek3r5p3viZjymeq12teMaU5eZVLVqefecWZZsrDnPUwXvZb3iRIXsVURqV5tSXIOmZKc+OWN0gdLLI9UA6Y+mQKqpnIeYJ4ntN0QU5gMs769e37act4OOv3ko62OOvQt5GO7Zno23CTjraY6oyiqLbLLwzhk+A3oj5Npii1JRluX6Z/OIJSgS/q5yZq1DELetz0ckHLpgoCaBL8oXBOk2W8beE3WdAyYUzWm9nLRO27Oi+T+aHOJOq8qEmnjiMznT+9nJomGgJoFuA31kR+mNWbOVXbVHXpr36lsh1B8HYna9swcRBAAxrvB8L5oQoaEHRB2+LcTpC2BN0Wc9bvJUhbwnDWFWR7fvfBbz6ndLTFVGfUmdqo9sPteOgmYh+d28i6H1R2nohkac4D5vdEcj7nq07Va0p324Yqo7jlM/FTr1sbGa/zqkMx5VFpznVueZnfOvzwKuO1PSXIdvVyTJUxlXemqbKmfAqvM5VzllH0OlW+IOVN9Dr9MNWvp+n1meo2lWcqr2LK48atTmZqg+Ishx9UnuK83gxTXTbvO6SeKehiCD/F8QnP1gCSzfsOqWd6LyGAAgCEhAAKABASAigAQEgIoAAAoRD9f4pY0RFFywQCAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "id": "171b9f84",
   "metadata": {},
   "source": [
    "- ![image.png](attachment:image.png)\n",
    "- 첫 파일을 열어보면 공백 2줄에 이어 가사가 시작됨을 알 수 있음\n",
    "- f.read().splitlines()는 한 라인에 있는 가사를 하나의 문장으로 구분하여 불러옴\n",
    "- 또한 파일은 총 49개이지만 그 안에 있는 가사를 한줄씩 데이터화 했을 경우 총 187,088개의 데이터가 존재하는것을 알 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303b762a",
   "metadata": {},
   "source": [
    "# 2. 데이터 전처리\n",
    "- 모든 실험에서 데이터의 전처리는 중요한 과정이지만, 특히 NLP 태스크에서는 더욱 중요함\n",
    "- 전처리의 여부, 진행과정에 따라 결과가 천차만별로 달라질 수 있기 때문임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdaa1720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7396\n"
     ]
    }
   ],
   "source": [
    "#단어 15개가 넘는 문장 갯수 확인\n",
    "\n",
    "c = 0\n",
    "for i in raw_corpus:\n",
    "    if len(i.split()) > 15:\n",
    "        c += 1\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d6e360b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence1:\n",
      " \n",
      "sentence2:\n",
      " \n",
      "sentence3:\n",
      " [Spoken Intro:]\n",
      "sentence4:\n",
      " You ever want something \n",
      "sentence5:\n",
      " that you know you shouldn't have \n",
      "sentence6:\n",
      " The more you know you shouldn't have it, \n",
      "sentence7:\n",
      " The more you want it \n",
      "sentence8:\n",
      " And then one day you get it, \n",
      "sentence9:\n",
      " It's so good too \n",
      "sentence10:\n",
      " But it's just like my girl \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(raw_corpus[:10])):\n",
    "    print(\"sentence{}:\\n {}\".format(i+1,raw_corpus[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5312f02d",
   "metadata": {},
   "source": [
    "- 1, 2번 문장은 길이가 0(공백)이기 때문에 제거를 해줘야 할 것으로 생각됨\n",
    "- 3번은 특수문자가 들어가 있으며, 필요없는 문장으로 판단되어 제거해줘야 할 것으로 생각됨\n",
    "- 또한 문자가 아닌 특수문자 같은 것들과 불필요한 공백들도 제거해줘야함\n",
    "- 그리고 제거된 문장에 모델의 input값에 맞게 시작위치와 끝위치를 나타내는 문자를 삽입해줌\n",
    "- 추가로 지나치게 긴 문장은 다른 데이터들이 과도한 Padding을 갖게 하므로 제거(단어의 수가 15개가 넘어가는것을 제거)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0fc480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip() #소문자로 바꾸고, 양쪽 공백을 지움\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) #특수문자 양쪽에 공백 추가\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) #여러개의 공백은 하나의 공백으로 교체\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) #-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 교체\n",
    "    sentence = sentence.strip() #양쪽 공백 제거\n",
    "    sentence = '<start> ' + sentence + ' <end>' #문장 시작에는 <start>, 끝에는 <end>를 추가\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d17aca3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168558\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    \n",
    "    if len(sentence) == 0 : continue #공백인 문장 제거\n",
    "    if len(sentence.split()) > 15 : continue #단어가 15개 이상인 문장 제거\n",
    "    if \"Intro\" in sentence : continue #분석에 중요하지 않은 문장 제거\n",
    "\n",
    "    preprocessed_sentence = preprocess_sentence(sentence)\n",
    "    corpus.append(preprocessed_sentence)\n",
    "    \n",
    "# corpus = list(OrderedDict.fromkeys(corpus)) #순서를 유지하되 중복된 노래 가사 제거\n",
    "\n",
    "print(len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb13581c",
   "metadata": {},
   "source": [
    "## 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98a8ec3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2    7  159 ...    0    0    0]\n",
      " [   2   17    7 ...    0    0    0]\n",
      " [   2    6   99 ...    0    0    0]\n",
      " ...\n",
      " [   2  308    1 ...    0    0    0]\n",
      " [   2  726    5 ... 2305   19 1148]\n",
      " [   2  726    5 ... 2305   19 1148]] <keras_preprocessing.text.Tokenizer object at 0x7fa540726f40>\n"
     ]
    }
   ],
   "source": [
    "def tokenize(corpus):\n",
    "    # 사전에 없는 단어는 '<unk>'처리\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=12000, #사전의 전체 단어 갯수\n",
    "        filters=' ', #별도로 전처리 로직 추가 가능\n",
    "        oov_token=\"<unk>\" #사전에 없는 단어 처리\n",
    "    )\n",
    "    # tokenizer.fit_on_texts(texts): 문자 데이터를 입력받아 리스트의 형태로 변환하는 메서드\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    \n",
    "    # 준비한 tokenizer를 이용해 corpus를 Tensor로 변환합니다\n",
    "    # tokenizer.texts_to_sequences(texts): 텍스트 안의 단어들을 숫자의 시퀀스 형태로 변환하는 메서드\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
    "    # 입력 데이터의 시퀀스 길이를 일정하게 맞춰줍니다\n",
    "    # 만약 시퀀스가 짧다면 문장 뒤에 패딩을 붙여 길이를 맞춰줍니다.\n",
    "    # 문장 앞에 패딩을 붙여 길이를 맞추고 싶다면 padding='pre'를 사용합니다\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post',truncating='post', maxlen=15)  #maxlen는 텐서 한 문장의 길이를 나타냄\n",
    "    \n",
    "    print(tensor,tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22258930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : <unk>\n",
      "2 : <start>\n",
      "3 : <end>\n",
      "4 : ,\n",
      "5 : i\n",
      "6 : the\n",
      "7 : you\n",
      "8 : and\n",
      "9 : a\n",
      "10 : to\n"
     ]
    }
   ],
   "source": [
    "#단어 사전 확인\n",
    "\n",
    "for idx in tokenizer.index_word:\n",
    "    print(idx, \":\", tokenizer.index_word[idx])\n",
    "\n",
    "    if idx >= 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1691bb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2   7 159  65 195   3   0   0   0   0   0   0   0   0]\n",
      "[  7 159  65 195   3   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "src_input = tensor[:, :-1]  #행은 다 들어가고 열에서 마지막것만 제거\n",
    "# tensor에서 <start>를 잘라내서 타겟 문장을 생성합니다.\n",
    "tgt_input = tensor[:, 1:]   #행은 다 들어가고 열에서 첫번째것만 제거\n",
    "\n",
    "print(src_input[0])#마지막 열의 토큰만 없음(end)\n",
    "print(tgt_input[0])#첫번째 열의 토큰만 없음(start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9503a4",
   "metadata": {},
   "source": [
    "# 3. 평가 데이터셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f64f3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, tgt_input, test_size=0.2, shuffle=True, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b4986b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(enc_train)\n",
    "BATCH_SIZE = 512\n",
    "steps_per_epoch = len(enc_train) // BATCH_SIZE\n",
    "\n",
    "VOCAB_SIZE = tokenizer.num_words + 1 #10000+ unk 1로 총 10001개의 사전 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4c270b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터셋 만들기\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train)).shuffle(BUFFER_SIZE)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "val_dataset  = tf.data.Dataset.from_tensor_slices((enc_val, dec_val))\n",
    "val_dataset  = val_dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16f5d2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Train: (134846, 14)\n",
      "Target Train: (134846, 14)\n"
     ]
    }
   ],
   "source": [
    "print(\"Source Train:\", enc_train.shape)\n",
    "print(\"Target Train:\", dec_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3474562a",
   "metadata": {},
   "source": [
    "# 4. 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "808a70c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        # Embedding 레이어, 2개의 LSTM 레이어, 1개의 Dense 레이어로 구성\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size) \n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "embedding_size =1024\n",
    "hidden_size = 2048\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size) # tokenizer.num_words에 +1인 이유는 문장에 없는 pad가 사용되었기 때문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43bac877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(512, 14, 12001), dtype=float32, numpy=\n",
       "array([[[ 5.0981366e-04,  2.9586579e-04, -2.4138368e-04, ...,\n",
       "         -1.2676860e-04, -5.2766118e-04, -1.5074124e-04],\n",
       "        [ 4.7207330e-05,  6.9492968e-04, -1.8736637e-04, ...,\n",
       "         -2.6227708e-04, -8.9079671e-04, -5.6201225e-04],\n",
       "        [-3.6083005e-04,  1.0014438e-03, -5.6520355e-04, ...,\n",
       "         -3.9616771e-04, -8.9518086e-04, -1.2011711e-03],\n",
       "        ...,\n",
       "        [ 1.3363869e-03, -3.8774556e-04,  2.7741288e-04, ...,\n",
       "         -1.9959873e-03, -1.6162307e-03, -1.8367515e-03],\n",
       "        [ 2.0307701e-03, -5.2778830e-04,  9.4975589e-04, ...,\n",
       "         -2.3666569e-03, -1.7837470e-03, -1.7243606e-03],\n",
       "        [ 2.6648783e-03, -5.1660329e-04,  1.6408662e-03, ...,\n",
       "         -2.7808286e-03, -1.9759783e-03, -1.6376951e-03]],\n",
       "\n",
       "       [[ 5.0981366e-04,  2.9586579e-04, -2.4138368e-04, ...,\n",
       "         -1.2676860e-04, -5.2766118e-04, -1.5074124e-04],\n",
       "        [ 1.0269537e-03,  1.7662288e-04, -4.0670243e-04, ...,\n",
       "         -3.0941493e-04, -6.4504863e-04, -1.4093274e-04],\n",
       "        [ 1.4821659e-03, -3.2052205e-05, -2.6417198e-04, ...,\n",
       "         -7.4064609e-04, -6.1456754e-04, -2.1239149e-04],\n",
       "        ...,\n",
       "        [ 2.1329569e-03, -6.4190693e-04,  1.0084683e-03, ...,\n",
       "         -1.2349761e-03, -2.6119349e-03, -8.3509390e-04],\n",
       "        [ 2.6777592e-03, -4.2671841e-04,  1.5826327e-03, ...,\n",
       "         -1.7267197e-03, -2.7526822e-03, -8.9181564e-04],\n",
       "        [ 3.1618425e-03, -1.6059513e-04,  2.1660628e-03, ...,\n",
       "         -2.2485333e-03, -2.8870562e-03, -9.8763779e-04]],\n",
       "\n",
       "       [[ 5.0981366e-04,  2.9586579e-04, -2.4138368e-04, ...,\n",
       "         -1.2676860e-04, -5.2766118e-04, -1.5074124e-04],\n",
       "        [ 6.1458017e-04, -3.8104467e-04, -2.9418821e-04, ...,\n",
       "         -6.9118483e-04, -6.3780713e-04, -1.6887483e-04],\n",
       "        [-2.0610919e-04, -6.6711579e-04, -1.9771614e-04, ...,\n",
       "         -5.9025385e-04, -8.4264093e-04,  4.3789233e-04],\n",
       "        ...,\n",
       "        [ 3.1101627e-03, -6.7418173e-04,  1.4909259e-04, ...,\n",
       "         -1.6259557e-03,  6.8749313e-04, -3.9930397e-04],\n",
       "        [ 3.4409743e-03, -6.3196837e-04,  7.1832351e-04, ...,\n",
       "         -1.9174373e-03,  2.1861737e-04, -5.1839318e-04],\n",
       "        [ 3.7372047e-03, -5.0390203e-04,  1.3513447e-03, ...,\n",
       "         -2.2860223e-03, -2.8750682e-04, -6.2855321e-04]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 5.0981366e-04,  2.9586579e-04, -2.4138368e-04, ...,\n",
       "         -1.2676860e-04, -5.2766118e-04, -1.5074124e-04],\n",
       "        [ 5.0571811e-04,  3.4581707e-04, -4.3676337e-04, ...,\n",
       "          5.1054906e-04, -6.9710618e-04, -9.4441282e-05],\n",
       "        [ 3.3463934e-04,  1.4164783e-04, -1.1491014e-03, ...,\n",
       "          7.1984204e-04, -3.8371363e-04,  2.1960681e-04],\n",
       "        ...,\n",
       "        [ 3.2793556e-03, -3.9217185e-04,  1.3146864e-03, ...,\n",
       "         -7.0026773e-04, -1.9460614e-03, -9.8089885e-04],\n",
       "        [ 3.7840926e-03, -1.9342368e-04,  1.9832931e-03, ...,\n",
       "         -1.4165699e-03, -2.1049676e-03, -1.1092995e-03],\n",
       "        [ 4.1943104e-03,  4.5749708e-05,  2.5867019e-03, ...,\n",
       "         -2.1125043e-03, -2.2788015e-03, -1.2558786e-03]],\n",
       "\n",
       "       [[ 5.0981366e-04,  2.9586579e-04, -2.4138368e-04, ...,\n",
       "         -1.2676860e-04, -5.2766118e-04, -1.5074124e-04],\n",
       "        [ 9.6270832e-04,  5.7778956e-04, -2.8317832e-04, ...,\n",
       "         -4.6532581e-04, -8.8349287e-04, -2.7830189e-04],\n",
       "        [ 9.3686261e-04,  7.6200027e-04, -3.9245418e-04, ...,\n",
       "         -4.9505342e-04, -1.1540117e-03, -6.9255481e-04],\n",
       "        ...,\n",
       "        [ 3.1567961e-03,  1.3039527e-04,  1.8025248e-03, ...,\n",
       "         -5.3947879e-04, -1.4697614e-03, -2.4714491e-03],\n",
       "        [ 3.4879206e-03,  2.4614975e-04,  2.3940690e-03, ...,\n",
       "         -1.1807497e-03, -1.6635804e-03, -2.3038231e-03],\n",
       "        [ 3.8005654e-03,  4.2028658e-04,  2.9520963e-03, ...,\n",
       "         -1.8311861e-03, -1.8659990e-03, -2.1908362e-03]],\n",
       "\n",
       "       [[ 5.0981366e-04,  2.9586579e-04, -2.4138368e-04, ...,\n",
       "         -1.2676860e-04, -5.2766118e-04, -1.5074124e-04],\n",
       "        [ 2.7857631e-04, -2.1852367e-04, -9.8514080e-04, ...,\n",
       "         -2.0704555e-04, -1.1724632e-03, -3.1406712e-04],\n",
       "        [ 2.4237906e-04, -3.1802661e-04, -1.1186455e-03, ...,\n",
       "          1.8531788e-05, -1.0101221e-03, -2.8306438e-04],\n",
       "        ...,\n",
       "        [ 1.9406241e-03,  4.0939526e-04,  8.8626443e-04, ...,\n",
       "         -1.5073497e-03, -1.5335452e-03, -1.7077706e-03],\n",
       "        [ 2.5420671e-03,  4.6219266e-04,  1.5553954e-03, ...,\n",
       "         -2.0766931e-03, -1.7665710e-03, -1.7231846e-03],\n",
       "        [ 3.0711920e-03,  5.9420947e-04,  2.1949015e-03, ...,\n",
       "         -2.6519541e-03, -2.0035396e-03, -1.7633492e-03]]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for src_sample, tgt_sample in train_dataset.take(1): break\n",
    "model(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1215b283",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  12289024  \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  multiple                  25174016  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                multiple                  33562624  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  24590049  \n",
      "=================================================================\n",
      "Total params: 95,615,713\n",
      "Trainable params: 95,615,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb28d540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "263/263 [==============================] - 276s 1s/step - loss: 3.5463 - val_loss: 3.1107\n",
      "Epoch 2/10\n",
      "263/263 [==============================] - 274s 1s/step - loss: 2.9408 - val_loss: 2.8622\n",
      "Epoch 3/10\n",
      "263/263 [==============================] - 274s 1s/step - loss: 2.6699 - val_loss: 2.6942\n",
      "Epoch 4/10\n",
      "263/263 [==============================] - 274s 1s/step - loss: 2.4165 - val_loss: 2.5625\n",
      "Epoch 5/10\n",
      "263/263 [==============================] - 274s 1s/step - loss: 2.1671 - val_loss: 2.4557\n",
      "Epoch 6/10\n",
      "263/263 [==============================] - 275s 1s/step - loss: 1.9230 - val_loss: 2.3695\n",
      "Epoch 7/10\n",
      "263/263 [==============================] - 275s 1s/step - loss: 1.6902 - val_loss: 2.3055\n",
      "Epoch 8/10\n",
      "263/263 [==============================] - 275s 1s/step - loss: 1.4810 - val_loss: 2.2653\n",
      "Epoch 9/10\n",
      "263/263 [==============================] - 275s 1s/step - loss: 1.3055 - val_loss: 2.2488\n",
      "Epoch 10/10\n",
      "263/263 [==============================] - 275s 1s/step - loss: 1.1703 - val_loss: 2.2495\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam() # Adam은 현재 가장 많이 사용하는 옵티마이저\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy( # 훈련 데이터의 라벨이 정수의 형태로 제공될 때 사용하는 손실함수\n",
    "    from_logits=True, # 기본값은 False이다. 모델에 의해 생성된 출력 값이 정규화되지 않았음을 손실 함수에 알려준다. 즉 softmax함수가 적용되지 않았다는걸 의미한다. \n",
    "    reduction='none'  # 기본값은 SUM이다. 각자 나오는 값의 반환 원할 때 None을 사용한다.\n",
    ")\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "history = model.fit(train_dataset, epochs=10, batch_size=512,\n",
    "          validation_data=val_dataset,validation_batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0e13eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#문장생성 함수 정의\n",
    "#모델에게 시작 문장을 전달하면 모델이 시작 문장을 바탕으로 작문을 진행\n",
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=15): #시작 문자열을 init_sentence 로 받으며 디폴트값은 <start> 를 받는다\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환합니다\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence]) #텍스트 안의 단어들을 숫자의 시퀀스의 형태로 변환\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    # 단어 하나씩 예측해 문장을 만듭니다\n",
    "    #    1. 입력받은 문장의 텐서를 입력합니다\n",
    "    #    2. 예측된 값 중 가장 높은 확률인 word index를 뽑아냅니다\n",
    "    #    3. 2에서 예측된 word index를 문장 뒤에 붙입니다\n",
    "    #    4. 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 마칩니다 (도달 하지 못하였으면 while 루프를 돌면서 다음 단어를 예측)\n",
    "    while True: #루프를 돌면서 init_sentence에 단어를 하나씩 생성성\n",
    "        # 1\n",
    "        predict = model(test_tensor) \n",
    "        # 2\n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
    "        # 3 \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "        # 4 \n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated #최종적으로 모델이 생성한 문장을 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63b8b771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i m the worlds greatest i m that little bit of hope <end> '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> i\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e417d2e",
   "metadata": {},
   "source": [
    "- 번역 : 나는 세상에서 가장 작은 희망입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7427399e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> we re gonna have a good time <end> '"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> we\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b60abd7",
   "metadata": {},
   "source": [
    "- 번역 : 우리는 좋은 시간을 보낼 것입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3acb160c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> love is a beautiful thing <end> '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82731db",
   "metadata": {},
   "source": [
    "- 번역 : 사랑은 아름다운 것입니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8800ded0",
   "metadata": {},
   "source": [
    "# 전체회고\n",
    "- 시도해본 방법\n",
    "1. layer 추가\n",
    "2. dropout 추가\n",
    "3. 하이퍼파라미터 변경\n",
    "4. 데이터 전처리\n",
    " - 사전 크기 변경\n",
    " - 중복된 노래 가사 제거\n",
    " - 15개 단어 이상이 존재하는 가사 제거\n",
    " - intro 등 불필요한 단어가 존재하는 가사 제거\n",
    " - model.fit 파라미터 추가\n",
    " - pad_sequences 패딩 위치 변경\n",
    " \n",
    "- 문장 생성 NLP는 처음 다뤄 보았음\n",
    "- 생각보다 loss 값이 안떨어져서 시간이 오래 걸렸음\n",
    "- loss값을 보면 결국 과적합이 된것으로 판단됨\n",
    "- 과적합을 방지하기위해 위에서 제시한 다양한 방법들과 이전 기수들것들을 참고하여 시도하였지만, 결국 2.2 이하로는 떨어뜨리지 못하였음\n",
    "- RNN이나 LSTM을 직접 만들어서 쓴것은 처음인데, 아직 부족한 점과 공부해야할 점이 많다고 생각됨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
